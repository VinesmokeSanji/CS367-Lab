{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Node\n",
    "It is the class for the node in the graph.\n",
    "\n",
    "It has the following attributes:\n",
    "- parent - the parent node\n",
    "- state - the state of the node\n",
    "- cost - the cost required to reach the node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, pcost, hcost, action = None):\n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.pcost = pcost\n",
    "        self.hcost = hcost\n",
    "        self.cost = pcost + hcost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(str(self.state.flatten()))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priority Queue\n",
    "The Priority Queue Class here is used to store the nodes along with the cost, and pop the node having the least cost for BFS\n",
    "\n",
    "It has the following methods:\n",
    "- push - Add node to queue\n",
    "- pop - Pop node having least cost\n",
    "- is_empty - To check if queue is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        self.hashes = {}\n",
    "        \n",
    "    def push(self, node):\n",
    "        if hash(node) not in self.hashes:\n",
    "            self.hashes[hash(node)] = 1\n",
    "            self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        state_cost = 10 ** 18\n",
    "        index = -1\n",
    "        for i in range(len(self.queue)):\n",
    "            if self.queue[i].cost<state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        return len(self.queue) == 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)\n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "\n",
    "The environment is where the agent acts. It has the following entities:\n",
    "- actions - The actions defined in the environment\n",
    "- depth - the maximum depth of the solution\n",
    "- goal_state - The goal state of the environment\n",
    "- start_state - The start state generated at the depth\n",
    "\n",
    "It has the following actions:\n",
    "1. up - Move the blank tile up\n",
    "2. down - Move the blank tile down\n",
    "3. right - Move the blank tile right\n",
    "4. left - Move the blank tile left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, start_state = None, goal_state = None):\n",
    "        self.actions = [1, 2, 3, 4]\n",
    "        if goal_state is None:\n",
    "            self.goal_state = self.generate_goal_state()\n",
    "        else:\n",
    "            self.goal_state = goal_state\n",
    "        if start_state is None:\n",
    "            self.start_state = self.generate_start_state()\n",
    "        else:\n",
    "            self.start_state = start_state\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        start = np.zeros((7, 7))\n",
    "        x = (0, 1, 5, 6)\n",
    "        y = (0, 1, 5, 6)\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                start[i][j] = -1;\n",
    "        x = (2, 3, 4)\n",
    "        y = range(7)\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                start[i][j] = 1\n",
    "                start[j][i] = 1\n",
    "        start[3][3] = 0\n",
    "        return start\n",
    "    \n",
    "    def generate_goal_state(self):\n",
    "        goal = np.zeros((7, 7))\n",
    "        x = (0, 1, 5, 6)\n",
    "        y = (0, 1, 5, 6)\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                goal[i][j] = -1;\n",
    "        x = (2, 3, 4)\n",
    "        y = range(7)\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                goal[i][j] = 0\n",
    "                goal[j][i] = 0\n",
    "        goal[3][3] = 1\n",
    "        return goal\n",
    "\n",
    "    def get_start_state(self):\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        new_states = []\n",
    "        spaces = []\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                if state[i][j] == 0:\n",
    "                    spaces.append((i, j))\n",
    "        for space in spaces:\n",
    "            x, y = space\n",
    "            if x > 1:\n",
    "                if state[x - 1][y] == 1 and state[x - 2][y] == 1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x - 2][y] = 0\n",
    "                    new_state[x - 1][y] = 0\n",
    "                    action = f'({x - 2}, {y}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            if x < 5:\n",
    "                if state[x + 1][y] == 1 and state[x + 2][y]==1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x + 2][y] = 0\n",
    "                    new_state[x + 1][y] = 0\n",
    "                    action = f'({x + 2}, {y}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            \n",
    "            if y > 1:\n",
    "                if state[x][y-1] == 1 and state[x][y-2] == 1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x][y - 2] = 0\n",
    "                    new_state[x][y - 1] = 0\n",
    "                    action = f'({x}, {y - 2}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            \n",
    "            if y < 5:\n",
    "                if state[x][y + 1] == 1 and state[x][y + 2] == 1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x][y + 2] = 0\n",
    "                    new_state[x][y + 1] = 0\n",
    "                    action = f'({x}, {y + 2}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                if state[i, j] != self.goal_state[i, j]:\n",
    "                    return False\n",
    "        return True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "The agent is the class that plays against the environment and finds the goal node. It has the following attributes:\n",
    "- frontier - This is the priority queue used to store the nodes to be explored.\n",
    "- explored - This is the dictionary which stores the explored nodes\n",
    "- start_state - Stores the start state\n",
    "- goal_state - Stores the goal state\n",
    "- env - Stores the environment\n",
    "- goal_node - Stores the goal node if found\n",
    "- heuristic - Stores the heuristic function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A-star search\n",
    "\n",
    "Using both heuristic cost and path cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        start = time()\n",
    "        while not self.frontier.is_empty():\n",
    "            curr_node = self.frontier.pop()\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "\n",
    "            for state in next_states:\n",
    "                hcost = self.heuristic(state[0])\n",
    "                node = Node(parent=curr_node, state=state[0], pcost=curr_node.pcost+1, hcost=hcost, action=state[1])\n",
    "                self.frontier.push(node)\n",
    "\n",
    "        end = time()\n",
    "        print(end - start)\n",
    "        return end - start\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Current step: \", step)\n",
    "            print(node.action)\n",
    "            step += 1\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic 0\n",
    "This is a null heuristic, returns 0 for all states as defined in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic0(curr_state):\n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic 1\n",
    "\n",
    "This is the manhattan distance, it returns the sum of the horizontal and vertical distances of the all marble in current state from center as defined in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic1(curr_state):\n",
    "    cost = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            if curr_state[i][j] == 1:\n",
    "                cost += abs(i - 3) + abs(j - 3)\n",
    "    return cost\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristic 2\n",
    "\n",
    "This is the exponential distance, it returns the 2<sup>max(h, v)</sup>, where h is the horizontal distance, and v is the vertical distance as defined in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heuristic2(curr_state):\n",
    "    cost = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            if curr_state[i][j] == 1:\n",
    "                cost += 2 ** (max(abs(i - 3), abs(j - 3)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n",
      "20.147850275039673\n",
      "Reached goal!\n",
      "19.787808895111084\n",
      "Reached goal!\n",
      "19.714818954467773\n",
      "Reached goal!\n",
      "19.619908809661865\n",
      "Reached goal!\n",
      "19.6410129070282\n",
      "Average time 19.78227996826172\n",
      "Total number of nodes explored: 33353\n",
      "Total number of nodes in frontier: 213\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(5):\n",
    "    agent = Agent(Environment(), heuristic2)\n",
    "    t += agent.run()\n",
    "print(\"Average time\", t / 5)\n",
    "print(\"Total number of nodes explored:\", len(agent.explored))\n",
    "print(\"Total number of nodes in frontier:\", len(agent.frontier))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best First Search\n",
    "\n",
    "Using Only Heuristic (Heuristic 2 from above cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        start = time()\n",
    "        while not self.frontier.is_empty():\n",
    "            curr_node = self.frontier.pop()\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "                \n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "\n",
    "            for state in next_states:\n",
    "                hcost = self.heuristic(state[0])\n",
    "                node = Node(parent=curr_node, state=state[0], pcost=0, hcost=hcost, action=state[1])\n",
    "                self.frontier.push(node)\n",
    "        \n",
    "        end = time()\n",
    "        print(end - start)\n",
    "        return end-start\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Current step: \",step)\n",
    "            print(node.action)\n",
    "            step+=1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n",
      "21.550740957260132\n",
      "Reached goal!\n",
      "21.515131950378418\n",
      "Reached goal!\n",
      "21.701796054840088\n",
      "Reached goal!\n",
      "21.305361032485962\n",
      "Reached goal!\n",
      "21.309140920639038\n",
      "Average time 21.476434183120727\n",
      "Total number of nodes explored: 35997\n",
      "Total number of nodes in frontier: 133\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(5):\n",
    "    agent = Agent(Environment(), heuristic2)\n",
    "    t += agent.run()\n",
    "    \n",
    "print(\"Average time\", t / 5)\n",
    "print(\"Total number of nodes explored:\", len(agent.explored))\n",
    "print(\"Total number of nodes in frontier:\", len(agent.frontier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Heuristic 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n",
      "84.54853415489197\n",
      "Reached goal!\n",
      "84.5747811794281\n",
      "Reached goal!\n",
      "84.08030009269714\n",
      "Reached goal!\n",
      "84.68268322944641\n",
      "Reached goal!\n",
      "84.95583200454712\n",
      "Average time  84.56842613220215\n",
      "Total number of nodes explored: 139663\n",
      "Total number of nodes in frontier: 146\n"
     ]
    }
   ],
   "source": [
    "tm = 0\n",
    "for i in range(5):\n",
    "    agent = Agent(Environment(), heuristic1)\n",
    "    tm += agent.run()\n",
    "print(\"Average time \", tm / 5)\n",
    "print(\"Total number of nodes explored:\", len(agent.explored))\n",
    "print(\"Total number of nodes in frontier:\", len(agent.frontier))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
